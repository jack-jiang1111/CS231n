{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"“homework3_resnet.ipynb”","provenance":[{"file_id":"14KzfhUg5u3CCbpPzVhC3Nfrs-7DJAxzp","timestamp":1634867761565},{"file_id":"1mGz6ZqYX6FDsVZYqEB36M-NRv7fl_ds4","timestamp":1602442883479}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"c5df3070bca745629b615a03bd8b6076":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4192809826442d48d9b01eb48138c86","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fce4835d853c456c8fe7757ec370b94d","IPY_MODEL_0eddb183833e4c40a202858214b8a3ac","IPY_MODEL_6c4a1d8bb8c6484cb7932a4585051cc7"]}},"a4192809826442d48d9b01eb48138c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fce4835d853c456c8fe7757ec370b94d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_593f0e06416048acb5465a9dae4fc911","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c84c878185754f179d038a23404ccb13"}},"0eddb183833e4c40a202858214b8a3ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8a37af5a89f64ce58d4a3217accf1c5d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef6d2319d3be456f8b02802544697405"}},"6c4a1d8bb8c6484cb7932a4585051cc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69b75c1912284b97b9905066e4e75266","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:11&lt;00:00, 16541900.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1eaaf76e1b2742c399d8527b22a9502a"}},"593f0e06416048acb5465a9dae4fc911":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c84c878185754f179d038a23404ccb13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a37af5a89f64ce58d4a3217accf1c5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef6d2319d3be456f8b02802544697405":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69b75c1912284b97b9905066e4e75266":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1eaaf76e1b2742c399d8527b22a9502a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"CM6FuhGPIMCO"},"source":["# ResNet for CIFAR-10\n","\n","You are going to implement [ResNet](https://arxiv.org/abs/1512.03385), one of the state-of-the-art CNN architecture.\n","Specifically, you are going to implement a variation of ResNet called [PreResNet](https://arxiv.org/abs/1603.05027), which locates activation before each convolutional layer (so called pre-activation).\n","You are going to first implement a plain building block, residual block, and then bottleneck block for really deep networks.\n","Finally, you will implement your own ResNet using those blocks.\n","\n","Throughout this part, we will follow the PyTorch default weight initialization for conciseness."]},{"cell_type":"markdown","metadata":{"id":"ubB_0e-UAOVK"},"source":["## Install starter code\n","We will continue using the utility functions that we've used for previous assignments: [`coutils` package](https://github.com/deepvision-class/starter-code). Run this cell to download and install it.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASkY27ZtA7Is","executionInfo":{"status":"ok","timestamp":1635989854630,"user_tz":360,"elapsed":5986,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"f64d6918-d9b1-4b47-c220-a2b9aa465438"},"source":["!pip install git+https://github.com/deepvision-class/starter-code"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/deepvision-class/starter-code\n","  Cloning https://github.com/deepvision-class/starter-code to /tmp/pip-req-build-b0z9f50n\n","  Running command git clone -q https://github.com/deepvision-class/starter-code /tmp/pip-req-build-b0z9f50n\n","Requirement already satisfied: pydrive in /usr/local/lib/python3.7/dist-packages (from Colab-Utils==0.1.dev0) (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (1.12.8)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (3.13)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (4.1.3)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (0.0.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.35.0)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.15.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (57.4.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (21.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (2.23.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.53.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.24.3)\n","Building wheels for collected packages: Colab-Utils\n","  Building wheel for Colab-Utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Colab-Utils: filename=Colab_Utils-0.1.dev0-py3-none-any.whl size=10307 sha256=fde1202d82270966a429bdcb80afdb73a881d105638889454048b7ca3bc0b506\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7oapymxc/wheels/eb/3c/88/465b0d78ef4a63d1f487c4208bd4691a448f05923eda0ef5f6\n","Successfully built Colab-Utils\n","Installing collected packages: Colab-Utils\n","Successfully installed Colab-Utils-0.1.dev0\n"]}]},{"cell_type":"markdown","metadata":{"id":"MzqbYcKdz6ew"},"source":["## Setup code\n","Run some setup code for this notebook."]},{"cell_type":"code","metadata":{"id":"Q8o3FxatIL_X","executionInfo":{"status":"ok","timestamp":1635989880346,"user_tz":360,"elapsed":25719,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["import coutils\n","from coutils import fix_random_seed\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","# for plotting\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["c5df3070bca745629b615a03bd8b6076","a4192809826442d48d9b01eb48138c86","fce4835d853c456c8fe7757ec370b94d","0eddb183833e4c40a202858214b8a3ac","6c4a1d8bb8c6484cb7932a4585051cc7","593f0e06416048acb5465a9dae4fc911","c84c878185754f179d038a23404ccb13","8a37af5a89f64ce58d4a3217accf1c5d","ef6d2319d3be456f8b02802544697405","69b75c1912284b97b9905066e4e75266","1eaaf76e1b2742c399d8527b22a9502a"]},"id":"-XB6NUX0IL_f","executionInfo":{"status":"ok","timestamp":1635989898670,"user_tz":360,"elapsed":18332,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"0df65068-947f-4e91-f1be-a0e1de5e9b8a"},"source":["NUM_TRAIN = 49000\n","\n","# The torchvision.transforms package provides tools for preprocessing data\n","# and for performing data augmentation; here we set up a transform to\n","# preprocess the data by subtracting the mean RGB value and dividing by the\n","# standard deviation of each RGB value; we've hardcoded the mean and std.\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","            ])\n","\n","# We set up a Dataset object for each split (train / val / test); Datasets load\n","# training examples one at a time, so we wrap each Dataset in a DataLoader which\n","# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n","# training set into train and val sets by passing a Sampler object to the\n","# DataLoader telling how it should sample from the underlying Dataset.\n","cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n","                             transform=transform)\n","loader_train = DataLoader(cifar10_train, batch_size=64, \n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n","                           transform=transform)\n","loader_val = DataLoader(cifar10_val, batch_size=64, \n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n","                            transform=transform)\n","loader_test = DataLoader(cifar10_test, batch_size=64)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5df3070bca745629b615a03bd8b6076","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"FiookQItIL_p"},"source":["Note that if CUDA is not enabled, `torch.cuda.is_available()` will return False and this notebook will fallback to CPU mode.\n","\n","The global variables `dtype` and `device` will control the data types throughout this assignment.\n","\n","We will be using `torch.float = torch.float32` for data and `torch.long = torch.int64` for labels.\n","\n","Please refer to https://pytorch.org/docs/stable/tensor_attributes.html#torch-dtype for more details about data types."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blz1sXlkIL_q","executionInfo":{"status":"ok","timestamp":1635989898670,"user_tz":360,"elapsed":7,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"721ab0fc-20d7-468a-e6cf-f6a65a4a5153"},"source":["dtype = torch.float\n","ltype = torch.long\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda:0')\n","else:\n","  device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","print('using device:', device)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"3efFpwV_IMBZ"},"source":["### Module API: Check Accuracy\n","Given the validation or test set, we can check the classification accuracy of a neural network. "]},{"cell_type":"code","metadata":{"id":"LpgKJLVbIMBb","executionInfo":{"status":"ok","timestamp":1635989898670,"user_tz":360,"elapsed":5,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["def check_accuracy(loader, model):\n","  if loader.dataset.train:\n","    print('Checking accuracy on validation set')\n","  else:\n","    print('Checking accuracy on test set')   \n","  num_correct = 0\n","  num_samples = 0\n","  model.eval()  # set model to evaluation mode\n","  with torch.no_grad():\n","    for x, y in loader:\n","      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","      y = y.to(device=device, dtype=ltype)\n","      scores = model(x)\n","      _, preds = scores.max(1)\n","      num_correct += (preds == y).sum()\n","      num_samples += preds.size(0)\n","    acc = float(num_correct) / num_samples\n","    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n","  return acc"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-tmOMi8SIMBj"},"source":["### Module API: Training Loop\n","We also use a slightly different training loop. Rather than updating the values of the weights ourselves, we use an Optimizer object from the `torch.optim` package, which abstract the notion of an optimization algorithm and provides implementations of most of the algorithms commonly used to optimize neural networks."]},{"cell_type":"code","metadata":{"id":"HLJjvtu1IMBm","executionInfo":{"status":"ok","timestamp":1635989898671,"user_tz":360,"elapsed":6,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["def adjust_learning_rate(optimizer, lrd, epoch, schedule):\n","  \"\"\"\n","  Multiply lrd to the learning rate if epoch is in schedule\n","  \n","  Inputs:\n","  - optimizer: An Optimizer object we will use to train the model\n","  - lrd: learning rate decay; a factor multiplied at scheduled epochs\n","  - epochs: the current epoch number\n","  - schedule: the list of epochs that requires learning rate update\n","  \n","  Returns: Nothing, but learning rate might be updated\n","  \"\"\"\n","  if epoch in schedule:\n","    for param_group in optimizer.param_groups:\n","      print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\n","      param_group['lr'] *= lrd\n","\n","def train(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[], verbose=True):\n","  \"\"\"\n","  Train a model on CIFAR-10 using the PyTorch Module API.\n","  \n","  Inputs:\n","  - model: A PyTorch Module giving the model to train.\n","  - optimizer: An Optimizer object we will use to train the model\n","  - epochs: (Optional) A Python integer giving the number of epochs to train for\n","  \n","  Returns: Nothing, but prints model accuracies during training.\n","  \"\"\"\n","  model = model.to(device=device)  # move the model parameters to CPU/GPU\n","  num_iters = epochs * len(loader_train)\n","  if verbose:\n","    num_prints = num_iters // print_every + 1\n","  else:\n","    num_prints = epochs\n","  acc_history = torch.zeros(num_prints, dtype=torch.float)\n","  iter_history = torch.zeros(num_prints, dtype=torch.long)\n","  for e in range(epochs):\n","    \n","    adjust_learning_rate(optimizer, learning_rate_decay, e, schedule)\n","    \n","    for t, (x, y) in enumerate(loader_train):\n","      model.train()  # put model to training mode\n","      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","      y = y.to(device=device, dtype=ltype)\n","\n","      scores = model(x)\n","      loss = F.cross_entropy(scores, y)\n","\n","      # Zero out all of the gradients for the variables which the optimizer\n","      # will update.\n","      optimizer.zero_grad()\n","\n","      # This is the backwards pass: compute the gradient of the loss with\n","      # respect to each  parameter of the model.\n","      loss.backward()\n","\n","      # Actually update the parameters of the model using the gradients\n","      # computed by the backwards pass.\n","      optimizer.step()\n","\n","      tt = t + e * len(loader_train)\n","\n","      if verbose and (tt % print_every == 0 or (e == epochs-1 and t == len(loader_train)-1)):\n","        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n","        acc = check_accuracy(loader_val, model)\n","        acc_history[tt // print_every] = acc\n","        iter_history[tt // print_every] = tt\n","        print()\n","      elif not verbose and (t == len(loader_train)-1):\n","        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n","        acc = check_accuracy(loader_val, model)\n","        acc_history[e] = acc\n","        iter_history[e] = tt\n","        print()\n","  return acc_history, iter_history"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f8pgYlKN9NLH"},"source":["## Plain block\n","\n","First, let's implement a plain block without residual connection.\n","PreResNet has a different order of layers from the previously implemented ones;\n","BatchNorm and ReLU precedes Conv.\n","The name of PreResNet comes form this pre-activation architecture.\n","Here, for downsampling, we don't introduce MaxPool layers explicitly, but use stride 2 in the first Conv layer in the block.\n","\n","Concretely, a plain block accepts a feature map of shape $C_{in} \\times H_{in} \\times W_{in}$ and produces a feature map of shape $C_{out} \\times H_{out} \\times W_{out}$. If the block performs downsampling, then $W_{out}=W_{in}/2$ and $H_{out}=H_{in}/2$; otherwise $H_{out}=H_{in}$ and $W_{out}=W_{in}$. The plain block consists of the following six layers in order:\n","\n","1. Spatial Batch normalization\n","2. ReLU\n","3. Convolutional layer with `Cout` 3x3 filters, zero-padding of 1, and stride 2 if downsampling; otherwise stride 1\n","4. Spatial Batch normalization\n","5. ReLU\n","6. Convolutional layer with `Cout` 3x3 filters, with zero-padding of 1\n"]},{"cell_type":"code","metadata":{"id":"-c4QBBj5-A3R","executionInfo":{"status":"ok","timestamp":1635989898671,"user_tz":360,"elapsed":5,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["class PlainBlock(nn.Module):\n","  def __init__(self, Cin, Cout, downsample=False):\n","    super().__init__()\n","\n","    self.net = None\n","    ############################################################################\n","    # TODO: Implement plain block.                                             #\n","    # Hint: Wrap your layers by nn.Sequential() to output a single module.     #\n","    #       You don't have use OrderedDict.                                    #\n","    # Inputs:                                                                  #\n","    # - Cin: number of input channels                                          #\n","    # - Cout: number of output channels                                        #\n","    # - downsample: add downsampling (a conv with stride=2) if True            #\n","    # Store the result in self.net.                                            #\n","    ############################################################################\n","    # Replace \"pass\" statement with your code\n","    middle = Cin\n","    down_middle = (Cin+1)//2\n","  \n","    if(downsample):\n","      model = nn.Sequential(\n","        nn.BatchNorm2d(Cin),\n","        nn.ReLU(),\n","        nn.Conv2d(Cin, down_middle, (3,3), padding=1,stride = 2),\n","        nn.BatchNorm2d(down_middle),\n","        nn.ReLU(),\n","        nn.Conv2d(down_middle, Cout, (3,3), padding=1),\n","      )\n","    else:\n","      model = nn.Sequential(\n","        nn.BatchNorm2d(Cin),\n","        nn.ReLU(),\n","        nn.Conv2d(Cin, middle, (3,3), padding=1,stride = 1),\n","        nn.BatchNorm2d(middle),\n","        nn.ReLU(),\n","        nn.Conv2d(middle, Cout, (3,3), padding=1),\n","      )\n","    self.net = model\n","    ############################################################################\n","    #                                 END OF YOUR CODE                         #\n","    ############################################################################\n","\n","  def forward(self, x):\n","    return self.net(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SofEF-vyAekS","executionInfo":{"status":"ok","timestamp":1635989899096,"user_tz":360,"elapsed":430,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"4a0ea6c0-38cc-40cf-b434-0f2bc0ef96dd"},"source":["data = torch.zeros(2, 3, 5, 6)\n","model = PlainBlock(3, 10)\n","if list(model(data).shape) == [2, 10, 5, 6]:\n","  print('The output of PlainBlock without downsampling has a *correct* dimension!')\n","else:\n","  print('The output of PlainBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n","\n","data = torch.zeros(2, 3, 5, 6)\n","model = PlainBlock(3, 10, downsample=True)\n","if list(model(data).shape) == [2, 10, 3, 3]:\n","  print('The output of PlainBlock with downsampling has a *correct* dimension!')\n","else:\n","  print('The output of PlainBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["The output of PlainBlock without downsampling has a *correct* dimension!\n","The output of PlainBlock with downsampling has a *correct* dimension!\n"]}]},{"cell_type":"markdown","metadata":{"id":"ASV5NdNADo3F"},"source":["## Residual block\n","\n","Next, let's implement a residual block.\n","A residual block adds a residual connection to a plain block. Let $\\mathcal{F}$ be a plain block; then the residual version  $\\mathcal{R}$ of the plain block $\\mathcal{F}$ computes:\n","\n","$\\mathcal{R}(x) = \\mathcal{F}(x) + x$\n","\n","However, this implementation will only work if the output from the plain block $\\mathcal{F}(x)$ has the same shape as the input $x$. Based on the plain block that we implemented above, there are two cases where the output of the plain block can have a different shape than the input:\n","\n","1. The number of output channels $C_{out}$ is different from the number of input channels $C_{in}$\n","2. The plain block $\\mathcal{F}$ performs spatial downsampling\n","\n","To deal with these cases, we need generalize our definition of the residual block and add a *shortcut connection* $\\mathcal{G}$:\n","\n","$\\mathcal{R}(x) = \\mathcal{F}(x) + \\mathcal{G}(x)$\n","\n","There are three cases for the shortcut connection $\\mathcal{G}$:\n","\n","1. If $C_{in}=C_{out}$ and $\\mathcal{F}$ does not perform downsampling, then $\\mathcal{F}(x)$ will have the same shape as $x$, so $\\mathcal{G}$ is the identity function: $\\mathcal{G}(x) = x$\n","2. If $C_{in} \\neq C_{out}$ and $\\mathcal{F}$ does not downsample, then $\\mathcal{G}$ is a 1x1 convolution with $C_{out}$ filters and stride 1.\n","3. If $\\mathcal{F}$ downsamples, then $\\mathcal{G}$ is a 1x1 convolution with $C_{out}$ filters and stride 2.\n","\n","In the code below, implement a residual block using the plain block we just defined:"]},{"cell_type":"code","metadata":{"id":"jzqJCUx6Do3I","executionInfo":{"status":"ok","timestamp":1635989899096,"user_tz":360,"elapsed":10,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["class ResidualBlock(nn.Module):\n","  def __init__(self, Cin, Cout, downsample=False):\n","    super().__init__()\n","\n","    self.block = None # F\n","    self.shortcut = None # G\n","    ############################################################################\n","    # TODO: Implement residual block using plain block. Hint: nn.Identity()    #\n","    # Inputs:                                                                  #\n","    # - Cin: number of input channels                                          #\n","    # - Cout: number of output channels                                        #\n","    # - downsample: add downsampling (a conv with stride=2) if True            #\n","    # Store the main block in self.block and the shortcut in self.shortcut.    #\n","    ############################################################################\n","    # Replace \"pass\" statement with your code\n","    if(not downsample and Cin==Cout):\n","      self.shortcut = nn.Identity()\n","    elif (not downsample and Cin!=Cout):\n","      self.shortcut = nn.Conv2d(Cin, Cout, (1,1),stride = 1)\n","    else:\n","      self.shortcut = nn.Conv2d(Cin, Cout, (1,1),stride = 2)\n","    self.block = PlainBlock(Cin,Cout,downsample)\n","    ############################################################################\n","    #                                 END OF YOUR CODE                         #\n","    ############################################################################\n","  \n","  def forward(self, x):\n","    return self.block(x) + self.shortcut(x)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMJ3-eI3Do3M","executionInfo":{"status":"ok","timestamp":1635989899097,"user_tz":360,"elapsed":11,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"e9b362bd-68c6-4117-d082-8d38d16b83ec"},"source":["data = torch.zeros(2, 3, 5, 6)\n","model = ResidualBlock(3, 10)\n","if list(model(data).shape) == [2, 10, 5, 6]:\n","  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n","else:\n","  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n","\n","data = torch.zeros(2, 3, 5, 6)\n","model = ResidualBlock(3, 10, downsample=True)\n","if list(model(data).shape) == [2, 10, 3, 3]:\n","  print('The output of ResidualBlock with downsampling has a *correct* dimension!')\n","else:\n","  print('The output of ResidualBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["The output of ResidualBlock without downsampling has a *correct* dimension!\n","The output of ResidualBlock with downsampling has a *correct* dimension!\n"]}]},{"cell_type":"markdown","metadata":{"id":"wrEzQeTBvNso"},"source":["## Residual stage\n","\n","So far, you implemented micro layers, which consists of several convolutional laters.\n","To efficiently build a deep neural network, we define a macro layer by repeating the micro layers.\n","\n","For your convenience, we provide the implementation below."]},{"cell_type":"code","metadata":{"id":"NhgWE6qTvVW6","executionInfo":{"status":"ok","timestamp":1635989899097,"user_tz":360,"elapsed":9,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["class ResNetStage(nn.Module):\n","  def __init__(self, Cin, Cout, num_blocks, downsample=True,\n","               block=ResidualBlock):\n","    super().__init__()\n","    blocks = [block(Cin, Cout, downsample)]\n","    for _ in range(num_blocks - 1):\n","      blocks.append(block(Cout, Cout))\n","    self.net = nn.Sequential(*blocks)\n","  \n","  def forward(self, x):\n","    return self.net(x)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I21i5J3AnbhM","executionInfo":{"status":"ok","timestamp":1635989899097,"user_tz":360,"elapsed":9,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"9e187e56-c796-4a60-e248-3dea24430a73"},"source":["print('Plain block stage:')\n","print(ResNetStage(3, 4, 2, block=PlainBlock))\n","print('Residual block stage:')\n","print(ResNetStage(3, 4, 2, block=ResidualBlock))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Plain block stage:\n","ResNetStage(\n","  (net): Sequential(\n","    (0): PlainBlock(\n","      (net): Sequential(\n","        (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (1): ReLU()\n","        (2): Conv2d(3, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (4): ReLU()\n","        (5): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (1): PlainBlock(\n","      (net): Sequential(\n","        (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (1): ReLU()\n","        (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (4): ReLU()\n","        (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n",")\n","Residual block stage:\n","ResNetStage(\n","  (net): Sequential(\n","    (0): ResidualBlock(\n","      (shortcut): Conv2d(3, 4, kernel_size=(1, 1), stride=(2, 2))\n","      (block): PlainBlock(\n","        (net): Sequential(\n","          (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","          (2): Conv2d(3, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (4): ReLU()\n","          (5): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (shortcut): Identity()\n","      (block): PlainBlock(\n","        (net): Sequential(\n","          (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","          (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (4): ReLU()\n","          (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"7l3-PNR9mlIb"},"source":["## Residual stem\n","\n","A \"stem\" layer is required at the beginning of the network, which increases the number of channels while keeping the other dimensions.\n","\n","For your convenience, we provide the implementation below."]},{"cell_type":"code","metadata":{"id":"eUvbubymmlIc","executionInfo":{"status":"ok","timestamp":1635989899098,"user_tz":360,"elapsed":9,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["class ResNetStem(nn.Module):\n","  def __init__(self, Cin=3, Cout=8):\n","    super().__init__()\n","    layers = [\n","        nn.Conv2d(Cin, Cout, kernel_size=3, padding=1, stride=1),\n","        nn.ReLU(),\n","    ]\n","    self.net = nn.Sequential(*layers)\n","    \n","  def forward(self, x):\n","    return self.net(x)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGzh0oVxm2Aw","executionInfo":{"status":"ok","timestamp":1635989899098,"user_tz":360,"elapsed":8,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"5ee3ed47-5ee7-4811-cca9-9012eb147dad"},"source":["data = torch.zeros(2, 3, 5, 6)\n","model = ResNetStem(3, 10)\n","if list(model(data).shape) == [2, 10, 5, 6]:\n","  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n","else:\n","  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The output of ResidualBlock without downsampling has a *correct* dimension!\n"]}]},{"cell_type":"markdown","metadata":{"id":"QGzn4Gp_sYBp"},"source":["## ResNet class\n","\n","Now, it is time to design the ResNet class using the blocks you implemented above!\n","\n","For general applicability, the class will get a dictionary of the architecture specification as an input, and parse it to build a CNN.\n","\n","Here we provide a couple of examples of specification;\n","`networks` is a collection of pre-defined network specifications, where each can be called by `get_resnet(key)`, where key is the name of the network, e.g., `get_resnet('resnet32')` will return a ResNet with 32 layers.\n","\n","Each specification consists of multiple tuples which correspond to a macro block (`ResNetStage`), and the values in each tuple implies `(num_in_channels, num_out_channels, num_blocks, do_downsample)`.\n","\n","To avoid dependency on the size of the input, ResNet has an average pooling at the end of the convolutional part, such that the size of the input tensor to the linear layer is always `(batch_size, stage_args[-1][1])`.\n","You may want to add an average pooling layer (`nn.AvgPool2d`), but it requires to know the size of the input.\n","Can you relax this requirement?\n","\n","**Hint**: You can perform average pooling in `forward`."]},{"cell_type":"code","metadata":{"id":"1iOOBoSgs-0X","executionInfo":{"status":"ok","timestamp":1635989899098,"user_tz":360,"elapsed":7,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["# example of specifications\n","networks = {\n","  'plain32': {\n","    'block': PlainBlock,\n","    'stage_args': [\n","      (8, 8, 5, False),\n","      (8, 16, 5, True),\n","      (16, 32, 5, True),\n","    ]\n","  },\n","  'resnet32': {\n","    'block': ResidualBlock,\n","    'stage_args': [\n","      (8, 8, 5, False),\n","      (8, 16, 5, True),\n","      (16, 32, 5, True),\n","    ]\n","  },\n","}"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVSeEzB7scmW","executionInfo":{"status":"ok","timestamp":1635989899099,"user_tz":360,"elapsed":8,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["import numpy as np\n","def flatten(x):\n","    N = x.shape[0] # read in N, C, H, W\n","    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n","class ResNet(nn.Module):\n","  def __init__(self, stage_args, Cin=3, block=ResidualBlock, num_classes=10):\n","    super().__init__()\n","\n","    self.cnn = None\n","    ############################################################################\n","    # TODO: Implement the convolutional part of ResNet using ResNetStem,       #\n","    #       ResNetStage, and wrap the modules by nn.Sequential.                #\n","    # Store the model in self.cnn.                                             #\n","    ############################################################################\n","    # Replace \"pass\" statement with your code\n","    layer1 = ResNetStem(Cin,stage_args[0][0])\n","    layers = []\n","    for layer in stage_args:\n","      #print(layer)\n","      middle_layer = ResNetStage(layer[0],layer[1],layer[2],layer[3],block)\n","      layers.append(middle_layer)\n","    self.cnn = nn.Sequential(layer1,*layers)\n","    print(stage_args)\n","    self.pooling = nn.AvgPool2d(8,padding=1)\n","\n","    ############################################################################\n","    #                                 END OF YOUR CODE                         #\n","    ############################################################################\n","    print(stage_args[-1][1])\n","    self.fc = nn.Linear(stage_args[-1][1], num_classes)\n","  \n","  def forward(self, x):\n","    scores = None\n","    ############################################################################\n","    # TODO: Implement the forward function of ResNet.                          #\n","    # Store the output in `scores`.                                            #\n","    ############################################################################\n","    # Replace \"pass\" statement with your code\n","    cnn = self.cnn(x)\n","    #cnn = flatten(cnn)\n","    #print(cnn.shape)\n","    cnn = self.pooling(cnn)\n","    #print(cnn.shape)\n","    cnn = flatten(cnn)\n","    scores = self.fc(cnn)\n","    ############################################################################\n","    #                                 END OF YOUR CODE                         #\n","    ############################################################################\n","    return scores\n","\n","def get_resnet(name):\n","  return ResNet(**networks[name])"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uqhp641H0P9Z"},"source":["## Train your model!\n","\n","Now let's train a few epochs of plain and residual networks with 32 layers on CIFAR.\n","You will see that deep non-residual networks don't converge well.\n","\n","**Caution: This takes a long time!**\n","\n","**Disclaimer: The performance of PreResNet-32 you will see here (~ 80%) would be lower than the best performance this model can achieve, because the convergence requires much more training.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRyYVBn60A58","executionInfo":{"status":"ok","timestamp":1635991566294,"user_tz":360,"elapsed":1667203,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"ccfd488b-509e-4425-ba04-ced799be242b"},"source":["# def init_module(model):\n","#   for m in model.modules():\n","#     if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","#       nn.init.kaiming_normal_(m.weight.data)\n","#       if m.bias is not None: nn.init.zeros_(m.bias.data)\n","#     elif isinstance(m, nn.BatchNorm2d):\n","#       nn.init.ones_(m.weight.data)\n","#       if m.bias is not None: nn.init.zeros_(m.bias.data)\n","\n","names = ['plain32', 'resnet32']\n","acc_history_dict = {}\n","iter_history_dict = {}\n","for name in names:\n","  fix_random_seed(0)\n","  print(name, '\\n')\n","  model = get_resnet(name)\n","\n","#   init_module(model)\n","  \n","  optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=1e-4)\n","\n","  acc_history, iter_history = train(model, optimizer, epochs=20, schedule=[6, 8], verbose=False)\n","  acc_history_dict[name] = acc_history\n","  iter_history_dict[name] = iter_history\n","\n","  # 64*32*8*8 max pooling =>64*32"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["plain32 \n","\n","[(8, 8, 5, False), (8, 16, 5, True), (16, 32, 5, True)]\n","32\n","Epoch 0, Iteration 765, loss = 1.5513\n","Checking accuracy on validation set\n","Got 358 / 1000 correct (35.80)\n","\n","Epoch 1, Iteration 1531, loss = 1.3734\n","Checking accuracy on validation set\n","Got 466 / 1000 correct (46.60)\n","\n","Epoch 2, Iteration 2297, loss = 1.0311\n","Checking accuracy on validation set\n","Got 435 / 1000 correct (43.50)\n","\n","Epoch 3, Iteration 3063, loss = 1.2367\n","Checking accuracy on validation set\n","Got 578 / 1000 correct (57.80)\n","\n","Epoch 4, Iteration 3829, loss = 1.2240\n","Checking accuracy on validation set\n","Got 574 / 1000 correct (57.40)\n","\n","Epoch 5, Iteration 4595, loss = 1.0225\n","Checking accuracy on validation set\n","Got 631 / 1000 correct (63.10)\n","\n","lr decay from 0.01 to 0.001\n","Epoch 6, Iteration 5361, loss = 1.0486\n","Checking accuracy on validation set\n","Got 683 / 1000 correct (68.30)\n","\n","Epoch 7, Iteration 6127, loss = 1.0534\n","Checking accuracy on validation set\n","Got 687 / 1000 correct (68.70)\n","\n","lr decay from 0.001 to 0.0001\n","Epoch 8, Iteration 6893, loss = 0.9232\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Epoch 9, Iteration 7659, loss = 0.9008\n","Checking accuracy on validation set\n","Got 690 / 1000 correct (69.00)\n","\n","Epoch 10, Iteration 8425, loss = 0.9859\n","Checking accuracy on validation set\n","Got 699 / 1000 correct (69.90)\n","\n","Epoch 11, Iteration 9191, loss = 0.6841\n","Checking accuracy on validation set\n","Got 698 / 1000 correct (69.80)\n","\n","Epoch 12, Iteration 9957, loss = 0.7343\n","Checking accuracy on validation set\n","Got 691 / 1000 correct (69.10)\n","\n","Epoch 13, Iteration 10723, loss = 0.8367\n","Checking accuracy on validation set\n","Got 699 / 1000 correct (69.90)\n","\n","Epoch 14, Iteration 11489, loss = 0.8590\n","Checking accuracy on validation set\n","Got 692 / 1000 correct (69.20)\n","\n","Epoch 15, Iteration 12255, loss = 0.7627\n","Checking accuracy on validation set\n","Got 697 / 1000 correct (69.70)\n","\n","Epoch 16, Iteration 13021, loss = 0.8744\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Epoch 17, Iteration 13787, loss = 0.7782\n","Checking accuracy on validation set\n","Got 696 / 1000 correct (69.60)\n","\n","Epoch 18, Iteration 14553, loss = 0.8721\n","Checking accuracy on validation set\n","Got 692 / 1000 correct (69.20)\n","\n","Epoch 19, Iteration 15319, loss = 1.2466\n","Checking accuracy on validation set\n","Got 692 / 1000 correct (69.20)\n","\n","resnet32 \n","\n","[(8, 8, 5, False), (8, 16, 5, True), (16, 32, 5, True)]\n","32\n","Epoch 0, Iteration 765, loss = 1.2312\n","Checking accuracy on validation set\n","Got 541 / 1000 correct (54.10)\n","\n","Epoch 1, Iteration 1531, loss = 1.0474\n","Checking accuracy on validation set\n","Got 579 / 1000 correct (57.90)\n","\n","Epoch 2, Iteration 2297, loss = 0.9480\n","Checking accuracy on validation set\n","Got 680 / 1000 correct (68.00)\n","\n","Epoch 3, Iteration 3063, loss = 0.8865\n","Checking accuracy on validation set\n","Got 621 / 1000 correct (62.10)\n","\n","Epoch 4, Iteration 3829, loss = 0.7296\n","Checking accuracy on validation set\n","Got 705 / 1000 correct (70.50)\n","\n","Epoch 5, Iteration 4595, loss = 0.7082\n","Checking accuracy on validation set\n","Got 711 / 1000 correct (71.10)\n","\n","lr decay from 0.01 to 0.001\n","Epoch 6, Iteration 5361, loss = 0.4133\n","Checking accuracy on validation set\n","Got 797 / 1000 correct (79.70)\n","\n","Epoch 7, Iteration 6127, loss = 0.2889\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","lr decay from 0.001 to 0.0001\n","Epoch 8, Iteration 6893, loss = 0.5213\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Epoch 9, Iteration 7659, loss = 0.2145\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Epoch 10, Iteration 8425, loss = 0.5012\n","Checking accuracy on validation set\n","Got 799 / 1000 correct (79.90)\n","\n","Epoch 11, Iteration 9191, loss = 0.6300\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Epoch 12, Iteration 9957, loss = 0.3752\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Epoch 13, Iteration 10723, loss = 0.4001\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Epoch 14, Iteration 11489, loss = 0.5474\n","Checking accuracy on validation set\n","Got 800 / 1000 correct (80.00)\n","\n","Epoch 15, Iteration 12255, loss = 0.7512\n","Checking accuracy on validation set\n","Got 800 / 1000 correct (80.00)\n","\n","Epoch 16, Iteration 13021, loss = 0.4029\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Epoch 17, Iteration 13787, loss = 0.5094\n","Checking accuracy on validation set\n","Got 806 / 1000 correct (80.60)\n","\n","Epoch 18, Iteration 14553, loss = 0.3664\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Epoch 19, Iteration 15319, loss = 0.3586\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"-u89CIFfzWWR","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1635991566800,"user_tz":360,"elapsed":508,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"6e753ddd-2cfa-4f53-c22a-8144dc4b3c0b"},"source":["import matplotlib.pyplot as plt\n","plt.title('Val accuracies')\n","for name in names:\n","  plt.plot(iter_history_dict[name], acc_history_dict[name], '-o')\n","plt.legend(names, loc='upper left')\n","plt.xlabel('iterations')\n","plt.ylabel('accuracy')\n","plt.gcf().set_size_inches(9, 4)\n","plt.show()"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 648x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"7Z31mvHGQT3y"},"source":["## Residual bottleneck block\n","\n","A bottleneck block is often useful for better efficiency, especially when importing a model to mobile devices.\n","The residual bottleneck block is similar to the standard residual block, but the plain block part has a different architecture:\n","it consists of 3 convolutional layers, and the first two convolutional layers have a smaller number of channels.\n","\n","Here is the specification of the bottleneck block:\n","\n","1. Spatial Batch normalization\n","2. ReLU\n","3. Convolutional layer with `Cout // 4` 1x1 filters, stride 2 if downsampling; otherwise stride 1\n","4. Spatial Batch normalization\n","5. ReLU\n","6. Convolutional layer with `Cout // 4` 3x3 filters, with zero-padding of 1\n","7. Spatial Batch normalization\n","8. ReLU\n","9. Convolutional layer with `Cout` 1x1 filters\n","\n","Don't forget to add the residual connection!"]},{"cell_type":"code","metadata":{"id":"TyuJhUd4BcZj","executionInfo":{"status":"ok","timestamp":1635991566800,"user_tz":360,"elapsed":13,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["class PlainBlock_for_Bottleneck(nn.Module):\n","  def __init__(self, Cin, Cout, downsample=False):\n","    super().__init__()\n","\n","    self.net = None\n","    middle = Cin\n","    down_middle = (Cin+1)//2\n","  \n","    if(downsample):\n","      model = nn.Sequential(\n","        nn.BatchNorm2d(Cin),\n","        nn.ReLU(),\n","        nn.Conv2d(Cin, Cout//4, (1,1),stride = 2),\n","        nn.BatchNorm2d(Cout//4),\n","        nn.ReLU(),\n","        nn.Conv2d(Cout//4, Cout, (3,3), padding=1),\n","        nn.BatchNorm2d(Cout),\n","        nn.ReLU(),\n","        nn.Conv2d(Cout, Cout, (1,1)),\n","      )\n","    else:\n","      model = nn.Sequential(\n","        nn.BatchNorm2d(Cin),\n","        nn.ReLU(),\n","        nn.Conv2d(Cin, Cout//4, (1,1),stride = 1),\n","        nn.BatchNorm2d(Cout//4),\n","        nn.ReLU(),\n","        nn.Conv2d(Cout//4, Cout, (3,3), padding=1),\n","        nn.BatchNorm2d(Cout),\n","        nn.ReLU(),\n","        nn.Conv2d(Cout, Cout, (1,1)),\n","      )\n","    self.net = model\n","    ############################################################################\n","    #                                 END OF YOUR CODE                         #\n","    ############################################################################\n","\n","  def forward(self, x):\n","    return self.net(x)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pUtZoVsQT31","executionInfo":{"status":"ok","timestamp":1635991566800,"user_tz":360,"elapsed":13,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}}},"source":["class ResidualBottleneckBlock(nn.Module):\n","  def __init__(self, Cin, Cout, downsample=False):\n","    super().__init__()\n","\n","    self.block = None\n","    self.shortcut = None\n","    ############################################################################\n","    # TODO: Implement residual bottleneck block.                               #\n","    # Inputs:                                                                  #\n","    # - Cin: number of input channels                                          #\n","    # - Cout: number of output channels                                        #\n","    # - downsample: add downsampling (a conv with stride=2) if True            #\n","    # Store the main block in self.block and the shortcut in self.shortcut.    #\n","    ############################################################################\n","    # Replace \"pass\" statement with your code\n","    if(not downsample and Cin==Cout):\n","      self.shortcut = nn.Identity()\n","    elif (not downsample and Cin!=Cout):\n","      self.shortcut = nn.Conv2d(Cin, Cout, (1,1),stride = 1)\n","    else:\n","      self.shortcut = nn.Conv2d(Cin, Cout, (1,1),stride = 2)\n","    self.block = PlainBlock_for_Bottleneck(Cin,Cout,downsample)\n","    ############################################################################\n","    #                                 END OF YOUR CODE                         #\n","    ############################################################################\n","\n","  def forward(self, x):\n","    return self.block(x) + self.shortcut(x)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqETnXH5QT37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635991566801,"user_tz":360,"elapsed":13,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"fca11e19-220d-4c0e-cf76-905b2515ba98"},"source":["data = torch.zeros(2, 3, 5, 6)\n","model = ResidualBottleneckBlock(3, 10)\n","if list(model(data).shape) == [2, 10, 5, 6]:\n","  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n","else:\n","  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n","\n","data = torch.zeros(2, 3, 5, 6)\n","model = ResidualBottleneckBlock(3, 10, downsample=True)\n","if list(model(data).shape) == [2, 10, 3, 3]:\n","  print('The output of ResidualBlock with downsampling has a *correct* dimension!')\n","else:\n","  print('The output of ResidualBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["The output of ResidualBlock without downsampling has a *correct* dimension!\n","The output of ResidualBlock with downsampling has a *correct* dimension!\n"]}]},{"cell_type":"markdown","metadata":{"id":"QnRc5hiHudMP"},"source":["By running the following script, you can check the architecture of ResNet-47 with bottlenecks.\n","\n","Caution: it is long!"]},{"cell_type":"code","metadata":{"id":"md6xmG-Aucrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635991566801,"user_tz":360,"elapsed":12,"user":{"displayName":"Zhongyi Jiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09975888319028773495"}},"outputId":"8750c092-abe5-418a-9c6b-1c1bc6e1ef71"},"source":["# example of specification\n","networks.update({\n","  'resnet47': {\n","    'block': ResidualBottleneckBlock,\n","    'stage_args': [\n","      (32, 32, 5, False),\n","      (32, 64, 5, True),\n","      (64, 128, 5, True),\n","    ],\n","  },\n","})\n","\n","print(get_resnet('resnet47'))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[(32, 32, 5, False), (32, 64, 5, True), (64, 128, 5, True)]\n","128\n","ResNet(\n","  (cnn): Sequential(\n","    (0): ResNetStem(\n","      (net): Sequential(\n","        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","    )\n","    (1): ResNetStage(\n","      (net): Sequential(\n","        (0): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (1): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (2): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (3): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (4): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (2): ResNetStage(\n","      (net): Sequential(\n","        (0): ResidualBottleneckBlock(\n","          (shortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(32, 16, kernel_size=(1, 1), stride=(2, 2))\n","              (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (1): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (2): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (3): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (4): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (3): ResNetStage(\n","      (net): Sequential(\n","        (0): ResidualBottleneckBlock(\n","          (shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2))\n","              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (1): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (2): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (3): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (4): ResidualBottleneckBlock(\n","          (shortcut): Identity()\n","          (block): PlainBlock_for_Bottleneck(\n","            (net): Sequential(\n","              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (1): ReLU()\n","              (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (4): ReLU()\n","              (5): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (7): ReLU()\n","              (8): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (pooling): AvgPool2d(kernel_size=8, stride=8, padding=1)\n","  (fc): Linear(in_features=128, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"81qgm-P5cQ4R"},"source":["*Many thanks to Justin Johnson and Stanford CS231n for permission to use their materials!*"]}]}